{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a2603fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.3\n",
      "0.5.2\n",
      "4.1.2\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import konlpy\n",
    "import gensim\n",
    "\n",
    "print(pandas.__version__)\n",
    "print(konlpy.__version__)\n",
    "print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fef0052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "np.random.seed(0)\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7bc8758",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('~/aiffel/project/FnGuide/finance_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf7ea87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>kor_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4841</th>\n",
       "      <td>negative</td>\n",
       "      <td>런던 마켓워치 -- 은행주의 반등이 FTSE 100지수의 약세를 상쇄하지 못하면서 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4842</th>\n",
       "      <td>neutral</td>\n",
       "      <td>린쿠스키아의 맥주 판매량은 416만 리터로 6.5% 감소했으며 카우노 알루스의 맥주...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4843</th>\n",
       "      <td>negative</td>\n",
       "      <td>영업이익은 2007년 68.8 mn에서 35.4 mn으로 떨어졌으며, 선박 판매 이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4844</th>\n",
       "      <td>negative</td>\n",
       "      <td>페이퍼 부문 순매출은 2008년 2분기 241.1 mn에서 2009년 2분기 221...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4845</th>\n",
       "      <td>negative</td>\n",
       "      <td>핀란드에서의 판매는 1월에 10.5% 감소한 반면, 국외에서의 판매는 17% 감소했다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4846 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        labels                                       kor_sentence\n",
       "0      neutral  Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...\n",
       "1      neutral  테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...\n",
       "2     negative  국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...\n",
       "3     positive  새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...\n",
       "4     positive  2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...\n",
       "...        ...                                                ...\n",
       "4841  negative  런던 마켓워치 -- 은행주의 반등이 FTSE 100지수의 약세를 상쇄하지 못하면서 ...\n",
       "4842   neutral  린쿠스키아의 맥주 판매량은 416만 리터로 6.5% 감소했으며 카우노 알루스의 맥주...\n",
       "4843  negative  영업이익은 2007년 68.8 mn에서 35.4 mn으로 떨어졌으며, 선박 판매 이...\n",
       "4844  negative  페이퍼 부문 순매출은 2008년 2분기 241.1 mn에서 2009년 2분기 221...\n",
       "4845  negative   핀란드에서의 판매는 1월에 10.5% 감소한 반면, 국외에서의 판매는 17% 감소했다.\n",
       "\n",
       "[4846 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['labels', 'kor_sentence']]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "241c4e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_304/3547878446.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['labels'] = data['labels'].replace({'negative': 0, 'neutral' : 1, 'positive': 2})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>kor_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4841</th>\n",
       "      <td>0</td>\n",
       "      <td>런던 마켓워치 -- 은행주의 반등이 FTSE 100지수의 약세를 상쇄하지 못하면서 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4842</th>\n",
       "      <td>1</td>\n",
       "      <td>린쿠스키아의 맥주 판매량은 416만 리터로 6.5% 감소했으며 카우노 알루스의 맥주...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4843</th>\n",
       "      <td>0</td>\n",
       "      <td>영업이익은 2007년 68.8 mn에서 35.4 mn으로 떨어졌으며, 선박 판매 이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4844</th>\n",
       "      <td>0</td>\n",
       "      <td>페이퍼 부문 순매출은 2008년 2분기 241.1 mn에서 2009년 2분기 221...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4845</th>\n",
       "      <td>0</td>\n",
       "      <td>핀란드에서의 판매는 1월에 10.5% 감소한 반면, 국외에서의 판매는 17% 감소했다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4827 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels                                       kor_sentence\n",
       "0          1  Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...\n",
       "1          1  테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...\n",
       "2          0  국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...\n",
       "3          2  새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...\n",
       "4          2  2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...\n",
       "...      ...                                                ...\n",
       "4841       0  런던 마켓워치 -- 은행주의 반등이 FTSE 100지수의 약세를 상쇄하지 못하면서 ...\n",
       "4842       1  린쿠스키아의 맥주 판매량은 416만 리터로 6.5% 감소했으며 카우노 알루스의 맥주...\n",
       "4843       0  영업이익은 2007년 68.8 mn에서 35.4 mn으로 떨어졌으며, 선박 판매 이...\n",
       "4844       0  페이퍼 부문 순매출은 2008년 2분기 241.1 mn에서 2009년 2분기 221...\n",
       "4845       0   핀란드에서의 판매는 1월에 10.5% 감소한 반면, 국외에서의 판매는 17% 감소했다.\n",
       "\n",
       "[4827 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['labels'] = data['labels'].replace({'negative': 0, 'neutral' : 1, 'positive': 2})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96135c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[~data['kor_sentence'].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "001af280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48fcadee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "sentences = data['kor_sentence'].tolist()\n",
    "labels = data['labels'].tolist()\n",
    "\n",
    "# Train-Test 데이터 분할\n",
    "train_sentences, test_sentences, train_labels, test_labels = train_test_split(sentences, labels, test_size=0.2, random_state=123)\n",
    "\n",
    "# Tokenizer 생성\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-base\")\n",
    "\n",
    "# 문장을 토큰으로 변환\n",
    "train_inputs = tokenizer.batch_encode_plus(\n",
    "    train_sentences,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "test_inputs = tokenizer.batch_encode_plus(\n",
    "    test_sentences,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# 레이블을 텐서로 변환\n",
    "train_labels = torch.tensor(train_labels)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "\n",
    "# 데이터를 DataLoader로 만듦\n",
    "train_dataset = TensorDataset(train_inputs['input_ids'], train_inputs['attention_mask'], train_labels)\n",
    "test_dataset = TensorDataset(test_inputs['input_ids'], test_inputs['attention_mask'], test_labels)\n",
    "\n",
    "batch_size = 8\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 모델 생성 및 불러오기\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"klue/roberta-base\", num_labels=3)\n",
    "\n",
    "# GPU 사용 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 옵티마이저 및 손실 함수 설정\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db6c4dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Train Loss: 0.5700 | Train Acc: 0.7692\n",
      "Test Loss: 0.4051 | Test Acc: 0.8292\n",
      "\n",
      "Epoch 2/10\n",
      "Train Loss: 0.3241 | Train Acc: 0.8778\n",
      "Test Loss: 0.3687 | Test Acc: 0.8551\n",
      "\n",
      "Epoch 3/10\n",
      "Train Loss: 0.2189 | Train Acc: 0.9239\n",
      "Test Loss: 0.4281 | Test Acc: 0.8458\n",
      "\n",
      "Epoch 4/10\n",
      "Train Loss: 0.1472 | Train Acc: 0.9485\n",
      "Test Loss: 0.4520 | Test Acc: 0.8437\n",
      "\n",
      "Epoch 5/10\n",
      "Train Loss: 0.1017 | Train Acc: 0.9658\n",
      "Test Loss: 0.6052 | Test Acc: 0.8333\n",
      "\n",
      "Epoch 6/10\n",
      "Train Loss: 0.0728 | Train Acc: 0.9769\n",
      "Test Loss: 0.6595 | Test Acc: 0.8437\n",
      "\n",
      "Epoch 7/10\n",
      "Train Loss: 0.0451 | Train Acc: 0.9899\n",
      "Test Loss: 0.5948 | Test Acc: 0.8416\n",
      "\n",
      "Epoch 8/10\n",
      "Train Loss: 0.0427 | Train Acc: 0.9881\n",
      "Test Loss: 0.6085 | Test Acc: 0.8406\n",
      "\n",
      "Epoch 9/10\n",
      "Train Loss: 0.0500 | Train Acc: 0.9850\n",
      "Test Loss: 0.6651 | Test Acc: 0.8478\n",
      "\n",
      "Epoch 10/10\n",
      "Train Loss: 0.0312 | Train Acc: 0.9907\n",
      "Test Loss: 0.7896 | Test Acc: 0.8427\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    \n",
    "    for batch in train_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        logits = outputs.logits\n",
    "        loss = loss_fn(logits, inputs['labels'])\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(logits, dim=1)\n",
    "        train_acc += (predicted == inputs['labels']).sum().item()\n",
    "        \n",
    "    train_loss /= len(train_dataloader)\n",
    "    train_acc /= len(train_dataset)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d15a470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.7896 | Test Accuracy: 0.8427\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.72      0.77       128\n",
      "     neutral       0.83      0.93      0.88       553\n",
      "    positive       0.87      0.73      0.80       285\n",
      "\n",
      "    accuracy                           0.84       966\n",
      "   macro avg       0.85      0.79      0.82       966\n",
      "weighted avg       0.84      0.84      0.84       966\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_acc = 0.0\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "    logits = outputs.logits\n",
    "    loss = loss_fn(logits, inputs['labels'])\n",
    "    \n",
    "    test_loss += loss.item()\n",
    "    _, predicted = torch.max(logits, dim=1)\n",
    "    test_acc += (predicted == inputs['labels']).sum().item()\n",
    "    \n",
    "    y_true.extend(inputs['labels'].tolist())\n",
    "    y_pred.extend(predicted.tolist())\n",
    "\n",
    "test_loss /= len(test_dataloader)\n",
    "test_acc /= len(test_dataset)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=['negative', 'neutral' ,'positive'])\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f} | Test Accuracy: {test_acc:.4f}\")\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fde8e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
